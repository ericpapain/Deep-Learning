# -*- coding: utf-8 -*-
"""TP2 indexation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15IJBPwJ_1s3vh9aFf1HatIKAvfJQH4AU
"""

import keras

import warnings

warnings.filterwarnings('ignore')
#/*pour ignorer les erreur des image */
from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

from keras.applications import VGG16

new_model=VGG16(weights="imagenet",include_top=False,input_shape=(32,32,3))

output=new_model.output



from keras.layers import Dense





from keras.layers import Dropout

from keras.layers import GlobalAveragePooling2D

output1=GlobalAveragePooling2D()(output)
output2=Dropout(0.15)(output1)

output3=Dense(1024,activation='relu')(output2)

output1=GlobalAveragePooling2D()(output)
output3=Dropout(0.15)(output1)

output3=Dense(1024,activation='relu')(output3)
 prediction=Dense(200,activation='softmax')(output3)

from keras.models import Model

model=Model(inputs=new_model.input, outputs=prediction)

for layer in model.layers[:5]:
  layer.trainable=False



from keras import optimizers

model.compile(loss="categorical_crossentropy", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=["accuracy"])

from keras.preprocessing.image import ImageDataGenerator

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras.callbacks import TensorBoard

train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)
ImageDataGenerator.LOAD_TRUNCATED_IMAGES = True
training_set = train_datagen.flow_from_directory(
      
        '/gdrive/My Drive/training_dataset',

        target_size=(32, 32),
          color_mode='rgb',
        batch_size=25,
           class_mode='categorical',
      
       )

test_set = test_datagen.flow_from_directory(
       '/gdrive/My Drive/test_set (1)',
        target_size=(32, 32),
          color_mode='rgb',
              batch_size=19,
            class_mode='categorical'
    
      
  
       )

history=model.fit_generator(
      training_set,
       steps_per_epoch=885,
        epochs=25,
       validation_data=test_set,
        validation_steps=291
        )

# Install the PyDrive wrapper & import libraries.
# This only needs to be done once in a notebook.
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client.
# This only needs to be done once in a notebook.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Create & upload a text file.
uploaded = drive.CreateFile({'title': 'Sample file.txt'})
uploaded.SetContentString('Sample upload file content')
uploaded.Upload()
print('Uploaded file with ID {}'.format(uploaded.get('id')))

model.save('/gdrive/My Drive/modelfinal.h5')

from google.colab import drive
drive.mount('/gdrive')

import matplotlib.pyplot as plt

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])

for i,layer in enumerate(model.layers):
  print(i,layer.name)

from keras.callbacks import TensorBoard

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
import os
from sklearn.decomposition import PCA
import imageio

df = train_datagen
 
my_dpi=96
plt.figure(figsize=(480/my_dpi, 480/my_dpi), dpi=my_dpi)
 
# Keep the 'specie' column appart + make it numeric for coloring
df['species']=pd.Categorical(df['species'])
my_color=df['species'].cat.codes
df = df.drop('species', 1)
 
# Run The PCA
pca = PCA(n_components=3)
pca.fit(df)
 
# Store results of PCA in a data frame
result=pd.DataFrame(pca.transform(df), columns=['PCA%i' % i for i in range(3)], index=df.index)

# 20 plots, for 20 different angles
for angle in range(70,210,2):
    # Plot initialisation
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    ax.scatter(result['PCA0'], result['PCA1'], result['PCA2'], c=my_color, cmap="Set2_r", s=60)

    # make simple, bare axis lines through space:
    xAxisLine = ((min(result['PCA0']), max(result['PCA0'])), (0, 0), (0,0))
    ax.plot(xAxisLine[0], xAxisLine[1], xAxisLine[2], 'r')
    yAxisLine = ((0, 0), (min(result['PCA1']), max(result['PCA1'])), (0,0))
    ax.plot(yAxisLine[0], yAxisLine[1], yAxisLine[2], 'r')
    zAxisLine = ((0, 0), (0,0), (min(result['PCA2']), max(result['PCA2'])))
    ax.plot(zAxisLine[0], zAxisLine[1], zAxisLine[2], 'r')
    
    ax.view_init(30,angle)

    # label the axes
    ax.set_xlabel("PC1")
    ax.set_ylabel("PC2")
    ax.set_zlabel("PC3")
    ax.set_title("PCA Iris Dataset")
    filename='PCA/PCA_angle'+str(angle)+'.png'
    plt.savefig(filename, dpi=96)

PCA

!apt-get -qq install PCA
